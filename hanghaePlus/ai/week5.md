항해플러스 AI코스 5주차 후기 – RAG로 더욱 신뢰할 수 있는 AI 서비스 개발하기

안녕하세요! 이번 주 항해플러스 AI 코스에서는 Instruction Tuning과 Multi-modal Large Language Model(MLLM), 그리고 Retrieval-Augmented Generation(RAG)을 깊이 있게 다뤘습니다. 이를 통해 저는 셀카 평가 LLM 애플리케이션인 “SelfieRate”를 개발했습니다. 이번 글에서는 제가 배운 내용과 과제를 하면서 겪었던 어려움, 그리고 이를 어떻게 해결했는지 자세히 공유하려고 합니다.

### 개요

5주차 학습은 크게 Instruction Tuning, Multi-modal LLM, 그리고 RAG라는 세 가지 주제로 나누어졌습니다. Instruction Tuning을 통해 모델이 특정 명령(instruction)에 정확히 응답할 수 있도록 학습시켰고, Multi-modal LLM을 통해 이미지와 텍스트를 동시에 입력받아 처리하는 방법을 배웠습니다. 마지막으로 RAG는 LLM이 외부 지식을 활용하여 더욱 정확하고 신뢰할 수 있는 답변을 생성할 수 있도록 하는 기술이었습니다.

저는 이 기술들을 활용하여 “SelfieRate”라는 셀카 평가 애플리케이션을 개발했는데, 사용자들이 자신의 셀카를 업로드하면 AI가 점수를 매기고 구체적인 개선 팁을 제공하는 서비스입니다.

### Instruction Tuning의 이해와 활용

Instruction Tuning은 단순한 텍스트 예측에서 벗어나 사용자의 명령을 정확하게 수행할 수 있도록 모델을 미세 조정하는 방법입니다. 특히 Supervised Fine-tuning(SFT)을 통해 질문과 답변이 명확히 구분된 데이터로 학습을 진행했는데, 이 과정에서 모델이 질문까지 함께 생성하는 문제가 발생할 수 있다는 점이 흥미로웠습니다. 이를 방지하기 위해 질문 부분에는 loss를 계산하지 않고, 답변 부분에만 집중적으로 loss를 계산하여 정확도를 높였습니다.

데이터는 주로 사람의 손으로 직접 만들거나 GPT를 통해 자동으로 생성했습니다. 특히 “Self-Instruct” 논문에서 소개된 방식으로 GPT가 자동으로 데이터를 생성하고 이를 필터링하여 효율적으로 데이터셋을 구축할 수 있었습니다. 이를 통해 실제로 작업 시간을 크게 절약할 수 있었습니다. 이 과정에서 데이터 품질 관리의 중요성을 다시금 깨닫게 되었으며, 데이터의 양과 질 사이의 균형을 맞추는 작업이 상당히 어려웠지만 의미 있었습니다.

### Multi-modal LLM을 활용한 이미지 분석

Multi-modal LLM은 이미지와 텍스트를 동시에 이해하는 모델입니다. Vision Transformer(ViT)를 이용해 이미지를 토큰 시퀀스로 변환하고, 이를 LLM에 입력으로 활용했습니다. 이 방식을 통해 셀카 이미지의 조명, 각도, 표정, 배경 등의 요소를 정확하게 분석할 수 있었습니다.

가장 어려웠던 부분은 이미지 전처리였는데, 이미지 크기와 품질을 최적화하여 모델 성능과 효율성을 모두 잡는 과정이 쉽지 않았습니다. 이를 해결하기 위해 PIL 라이브러리를 사용해 이미지를 적절히 리사이징하고 압축하여 효율적으로 처리했습니다. 또한 이미지 품질이 모델의 성능에 얼마나 중요한 영향을 미치는지 실험적으로 확인할 수 있었던 점이 매우 유익했습니다.

### RAG를 활용한 외부 정보 활용

RAG는 사용자의 질문에 외부 자료를 활용하여 답변을 보강하는 기술입니다. 기본 과제로 주어진 블로그의 정보를 GPT와 결합하여 “ALL-in 코딩 공모전 수상작”을 요약하는 챗봇을 구현했습니다. 이전 코드에서 웹사이트 HTML 구조가 달라지는 문제가 있었지만, BeautifulSoup의 HTML 클래스와 태그를 꼼꼼히 분석하여 올바르게 수정할 수 있었습니다.

심화 과제에서는 이 기술을 셀카 평가 서비스에 접목해, 평가 기준과 개선 팁을 더욱 풍부하게 제공할 수 있도록 했습니다. 이를 통해 모델의 신뢰성을 높일 수 있었습니다. 특히 외부 데이터를 어떻게 효율적으로 추출하고 활용할 수 있을지 고민하는 과정에서 많은 것을 배웠습니다.

### SelfieRate 서비스 개발 과정

제가 개발한 “SelfieRate”는 셀카 이미지에 점수를 매기고, 이유와 개선 팁을 명확하게 제공하는 서비스입니다. GPT-4 Vision 모델과 LangChain을 사용하여 평가 기준을 구조화하고, 이미지를 처리했습니다. 특히 LangChain의 체인을 활용하여 prompt를 구성하고 실행하는 과정을 효율적으로 관리할 수 있었습니다.

서비스를 개발하면서 가장 어려웠던 점은 Prompt Engineering이었습니다. 처음에는 모델의 답변이 너무 일반적이었으나, 평가 기준을 명확히 구체화하고, 예시를 충분히 제공하여 모델의 출력이 보다 구체적이고 유용하게 나올 수 있도록 개선했습니다. 또한 사용자의 관점에서 어떤 답변이 가장 실질적으로 유용할지 끊임없이 고민했습니다.

### 마무리

이번 5주차 학습을 통해 저는 Instruction Tuning, Multi-modal LLM, 그리고 RAG라는 강력한 기술들을 익혔고, 이를 실제 프로젝트에 적용하며 실질적인 경험을 쌓았습니다. 특히 Prompt Engineering의 중요성을 깨닫고, 보다 효과적인 프롬프팅 방법을 연구하게 되었습니다.

“SelfieRate” 서비스를 개발하면서 다음과 같은 교훈을 얻었습니다:

Prompt의 중요성: 모델의 성능을 극대화하기 위해서는 프롬프팅 전략이 매우 중요합니다. 모델이 어떤 정보를 필요로 하는지 명확히 전달해야 합니다.

멀티모달 입력 처리의 효율성: 이미지를 처리할 때는 효율성을 고려한 최적화 작업이 필수적입니다. 이 과정에서 이미지 전처리 기법을 더 깊이 이해할 수 있었습니다.

RAG의 활용성: 외부 자료를 활용하면 모델의 신뢰성을 크게 향상시킬 수 있다는 점을 명확히 경험할 수 있었습니다.

이번 프로젝트를 통해 AI 기반 서비스 개발에 대한 자신감을 얻었으며, 앞으로 더 다양한 분야에 적용할 수 있는 역량을 갖추었다고 생각합니다. 앞으로의 학습과 프로젝트들도 더욱 기대가 됩니다. 긴 글 읽어주셔서 감사합니다!

항해 플러스 — 추천인 코드: CF7LUQ

#항해99 #항해플러스AI후기 #AI개발자 #LLM